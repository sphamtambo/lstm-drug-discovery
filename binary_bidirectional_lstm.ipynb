{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfe4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f443ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7451242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles activity  HIV_active\n",
       "0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n",
       "1  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n",
       "2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n",
       "3    Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n",
       "4                             O=S(=O)(O)CCS(=O)(=O)O       CI           0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/HIV.csv\")\n",
    "df = df[:2000]\n",
    "print(f\"size: {df.shape[0]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba5bfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1e48abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = CustomDataset(df.smiles, df.HIV_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa34668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1600.0], [200.0], [200.0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "[0.8 *len(dataset)], [0.1 *len(dataset)], [0.1 *len(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "841ff2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [int(0.8*len(dataset)), int(0.1*len(dataset)), int(0.1*len(dataset))]) # 80, 10, 10\n",
    "len(train_dataset + test_dataset + val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30d62ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [1600, 200, 200]) # 80, 10, 10\n",
    "len(train_dataset + test_dataset + val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf5f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID:\n",
      "  N#CC(=Cc1ccccc1)c1ccc(Cl)cc1\n",
      "Label:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "for smiles, labels in train_dataset:\n",
    "    print(\"Input ID:\\n \" ,smiles)\n",
    "    print(\"Label:\\n\" ,labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37109c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/topazape/LSTM_Chem/blob/master/lstm_chem/utils/smiles_tokenizer2.py\n",
    "\n",
    "class SmilesTokenizer(object):\n",
    "    def __init__(self):\n",
    "        atoms = [\n",
    "            'Al', 'As', 'B', 'Br', 'C', 'Cl', 'F', 'H', 'I', 'K', 'Li', 'N',\n",
    "            'Na', 'O', 'P', 'S', 'Se', 'Si', 'Te'\n",
    "        ]\n",
    "        special = [\n",
    "            '(', ')', '[', ']', '=', '#', '%', '0', '1', '2', '3', '4', '5',\n",
    "            '6', '7', '8', '9', '+', '-', 'se', 'te', 'c', 'n', 'o', 's'\n",
    "        ]\n",
    "\n",
    "        self.table = sorted(atoms, key=len, reverse=True) + special \n",
    "\n",
    "        self.table_2_chars = list(filter(lambda x: len(x) == 2, self.table))\n",
    "        self.table_1_chars = list(filter(lambda x: len(x) == 1, self.table))\n",
    "        self.vocab_dict = {}\n",
    "\n",
    "    def tokenize(self, smiles):\n",
    "        smiles = smiles + ' '\n",
    "        N = len(smiles)\n",
    "        token = []\n",
    "        i = 0\n",
    "        while (i < N):\n",
    "            c1 = smiles[i]\n",
    "            c2 = smiles[i:i + 2]\n",
    "\n",
    "            if c2 in self.table_2_chars:\n",
    "                token.append(c2)\n",
    "                i += 2\n",
    "                continue\n",
    "\n",
    "            if c1 in self.table_1_chars:\n",
    "                token.append(c1)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return np.asarray(token, dtype=object)\n",
    "        \n",
    "    def vocaburaly(self):\n",
    "        vocab_dict = {}\n",
    "        for i, tok in enumerate(self.table):\n",
    "            vocab_dict[tok] = i\n",
    "        return vocab_dict\n",
    "    \n",
    "    def index_encode(self, tokenized_smiles):\n",
    "        vocab_dict = {}\n",
    "        for i, tok in enumerate(self.table):\n",
    "            vocab_dict[tok] = i\n",
    "        encoded = [vocab_dict[t] for t in tokenized_smiles ]\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4632b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SmilesTokenizer()\n",
    "tokens = [tokenizer.tokenize(x) for x in df.smiles]\n",
    "vocabulary = tokenizer.vocaburaly()\n",
    "indexed_smiles = [tokenizer.index_encode(x) for x in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e9ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "sorted_by_freq_tuples = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab1 = vocab(ordered_dict)\n",
    "vocab1.insert_token(\"<pad>\", 0)\n",
    "vocab1.insert_token(\"<unk>\", 1)\n",
    "vocab1.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2334133c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', 's', 'o', 'n', 'c', 'te', 'se', '-', '+']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab1.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80a36c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29, 22, 27, 26, 22, 29, 25]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline = lambda x: [vocab1[token] for token in tokenizer.tokenize(x)]\n",
    "text_pipeline(\"O=S(=O)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ff9bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline = lambda x: 1. if x == 0. else 1.\n",
    "label_pipeline(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074984fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for   _text, _label in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text),\n",
    "                                      dtype=torch.long)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list,\n",
    "                                 dtype=torch.float)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list,\n",
    "                                                     batch_first=True)  \n",
    "    return padded_text_list, label_list, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24a8018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[35,  5, 18,  ...,  0,  0,  0],\n",
       "         [35, 35, 35,  ...,  0,  0,  0],\n",
       "         [35, 35, 26,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [29, 22,  5,  ...,  0,  0,  0],\n",
       "         [27,  5, 18,  ...,  0,  0,  0],\n",
       "         [35, 35, 29,  ...,  0,  0,  0]]),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " tensor([ 16,  20,  18,  77,  44,  24,  36,  28,  57,  41,  52, 109,  21,  22,\n",
       "          26,  26,  25,  19,  87,  28,  29,  33,  21,  67,  61,  47,  30,  30,\n",
       "          40,  22,  15,  29,  29,  22,  30,  62,  41,  25,  47,  74,  22,  43,\n",
       "          26,  26,  51,  25,  32,   9,  23,  25,  15,  33,  33,  39,  73,  33,\n",
       "          32,  21,  32,  25,  28,  51,  29,  20,  64,  37,  31,  54,  36,  32,\n",
       "          55,  99,  22,  35,  30,  15,  70,  31,  41,  30,  19,  27,  56,  17,\n",
       "          23,  28,  58,  50,  41,  21,  21,   6,  20,  19,  37,  41,  22,  54,\n",
       "          24,  36,  15,  35, 119,  33,  35,  19,  36,  25,  36,  45,  51,  31,\n",
       "          20,  43,  75,  33,  42,  57,  59,  33,  31, 215, 102,  70,  32,  17,\n",
       "          27,  49,  16,  25,  33,  38,  57,  23,  20,  31, 112,  28,  38, 107,\n",
       "          16,  39,  54,  62,  17,  42,  26,  39, 101,  23,  34,  39,  27,  23,\n",
       "          36,  37,  38, 100,  32,  20,  30,  10,  39,  91,  28,  56,  45,  42,\n",
       "          24,  40,  33,   4,  62,  24,  35,  51,  13,  23,  30,  45,  59,  39,\n",
       "          33,  27,  30,  22,  30,  37,  28,  37,  33,  31,  39,  38,  31,  54,\n",
       "          38,  50,  20,  27]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_batch(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b449784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=10, shuffle=True, collate_fn=collate_batch)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=10, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "306151be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35, 35, 26, 22, 29, 25, 35, 24, 28, 33, 23, 26,  5, 18,  5,  5,  5,  5,\n",
      "          5, 18, 25, 26,  5, 18,  5,  5,  5,  5,  5, 18, 25,  5, 18,  5,  5,  5,\n",
      "          5,  5, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([39, 22, 34, 36, 39, 67, 14, 23, 25, 80])\n",
      "torch.Size([10, 80])\n"
     ]
    }
   ],
   "source": [
    "text_batch, label_batch, length_batch = next(iter(test_dataloader))\n",
    "print(text_batch[:1])\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17a48af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## building an rnn model\n",
    "## many to one classificaton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0b8404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size,\n",
    "                 num_layers, fc_hidden_size, output_size):\n",
    "        super(). __init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim (embedding))\n",
    "        # batch_dim = number of samples per batch\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers,\n",
    "                           batch_first=True, bidirectional=True) \n",
    "        # only use the hidden_size, since its a many to one\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size * num_layers, fc_hidden_size)  \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        # regularization to avoid overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # output_size, use 1 for binary classification\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, output_size) \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text dim: [sentence length, batch size]\n",
    "        # text_length = [batch size]\n",
    "        \n",
    "        # [sentence len, batch size] => [sentence len, batch size, embedding size]\n",
    "        out = self.embedding(text)\n",
    "        \n",
    "        # pack sequence to avoid using <paddings> during computations (saves computations)\n",
    "        # lengths needs to be on cpu\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, text_lengths.to('cpu'),\n",
    "                                                enforce_sorted=False, batch_first=True)\n",
    "        # =>  [batch_size, sentence len,  embedding dim]\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        out, (hidden, cell) = self.rnn(out) ## lstm with input, hidden, and internal (cell) state\n",
    "        # out dim: [batch size, sentence length, hidden dim]\n",
    "        # cell dim: [num layers, batch size, hidden dim]\n",
    "        # hidden dim: [num_layers, batch_size, hidden dim]\n",
    "        \n",
    "        # use final hidden state from the last layer as an input to fc1\n",
    "        # Index hidden state of last time step\n",
    "        # hidden.size() --> [num_layers, batch_size, hidden dim]\n",
    "        \n",
    "        # final layer foward hidden state     \n",
    "        hidden_fwd = hidden[-2]\n",
    "        # final layer backwaed hidden state \n",
    "        hidden_bck = hidden[-1]\n",
    "        \n",
    "        # concatenate the 2 layers to pass to linear layer\n",
    "        # hidden_fwd/bck = [batch size, hid dim]\n",
    "        out = torch.cat((hidden_fwd, hidden_bck), dim = 1)\n",
    "        # out = [batch size, hid dim * 2]\n",
    "\n",
    "        out = self.fc1(out) ## first dense layer\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out) ## final layer\n",
    "        out = self.sigmoid(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a426fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab1) ## len of vocab size\n",
    "embed_dim = 70 ## input size, usually around 50-500 dimensions\n",
    "num_layers = 2 ## number of recurrent layers, 2 would mean stacking 2 layers to form stacked LSTM\n",
    "rnn_hidden_size = 100 ## usually around 100-500 dimensions\n",
    "fc_hidden_size = 100 ## usually around 100-500 dimensions\n",
    "output_size = 1 ## since the output is between 0 and 1, thus 1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90638f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we will instantiate the class LSTM1 object.\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size,\n",
    "            num_layers, fc_hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91feee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(45, 70, padding_idx=0)\n",
       "  (rnn): LSTM(70, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f744f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    # model training mode (gradient computation)\n",
    "    model.train()\n",
    "    # initailiz acc, and loss at zero \n",
    "    total_acc, total_loss = 0, 0\n",
    "    for idx, (text, label, length) in enumerate (dataloader):\n",
    "        # reset gradients to zero before each instance\n",
    "        optimizer.zero_grad()\n",
    "        # label predictions (forward papagation)\n",
    "        # squeeze(1) => drop superficial one dimensional from a tensor\n",
    "        predicted_label = model(text, length).squeeze(1) # or [:,0]\n",
    "        # loss calculation\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # compute gradients (backward propagation) \n",
    "        # to minimize loss functions with gradient descent\n",
    "        loss.backward()\n",
    "        # update parameters based on the computed gradients\n",
    "        optimizer.step()\n",
    "        ## logging\n",
    "        if not idx % 50:\n",
    "            print('| Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f'\n",
    "                  %(epoch +1, num_epochs, idx, len(dataloader), loss))\n",
    "        # compute total accuracy\n",
    "        # if pred label is >=0.5 to probability of true truth accuracy count increases\n",
    "        # summation of the largest value which yields predicted class label\n",
    "        total_acc += ((predicted_label >= 0.5).float() == label).float().sum().item()\n",
    "        # compute total loss after back prop and parameter update\n",
    "        total_loss += loss.item() * label.size(0)\n",
    "    # compare true labels with the predicted labels to compute accuracy\n",
    "    return total_acc/len(dataloader.dataset), \\\n",
    "            total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5b6545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    # model evaluation mode (no gradient computation)\n",
    "    model.eval()\n",
    "    # initailize acc, and loss at zero \n",
    "    total_acc, total_loss = 0, 0\n",
    "    # disabling gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for text, label, length in dataloader:\n",
    "            # label predictions (forward papagation)\n",
    "            # squeeze(1) => drop superficial one dimensional from a tensor\n",
    "            predicted_label = model(text, length).squeeze(1) # reshape\n",
    "            # loss calculation\n",
    "            loss = loss_fn(predicted_label, label)\n",
    "            # compute total accuracy\n",
    "            # if pred label is >=0.5 to probability of true truth accuracy count increases\n",
    "            # summation of the largest value which yields predicted class label\n",
    "            total_acc += ((predicted_label >= 0.5).float() == label).float().sum().item()\n",
    "            # compute total loss after back prop and parameter update\n",
    "            total_loss += loss.item() * label.size(0)\n",
    "            # compare true labels with the predicted labels to compute accuracy\n",
    "        # compare true labels with the predicted labels to compute accuracy\n",
    "        return total_acc/len(dataloader.dataset), \\\n",
    "                total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ef067ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binnary classification we use\n",
    "# single class membership probability output (binary cross entropy loss)\n",
    "# although BCELoss\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "# Adam Optimizer to update parameters based on the computed gradients\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c632c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 001/005 | Batch 0000/0160 | Loss: 0.3133\n",
      "| Epoch: 001/005 | Batch 0050/0160 | Loss: 0.3133\n",
      "| Epoch: 001/005 | Batch 0100/0160 | Loss: 0.3133\n",
      "| Epoch: 001/005 | Batch 0150/0160 | Loss: 0.3133\n",
      "| Epoch: 001/005 | Train Acc: 100.00% | Valid. Acc: 100.00%\n",
      "| Time elapsed: 0.53 min\n",
      "| Epoch: 002/005 | Batch 0000/0160 | Loss: 0.3133\n",
      "| Epoch: 002/005 | Batch 0050/0160 | Loss: 0.3133\n",
      "| Epoch: 002/005 | Batch 0100/0160 | Loss: 0.3133\n",
      "| Epoch: 002/005 | Batch 0150/0160 | Loss: 0.3133\n",
      "| Epoch: 002/005 | Train Acc: 100.00% | Valid. Acc: 100.00%\n",
      "| Time elapsed: 1.12 min\n",
      "| Epoch: 003/005 | Batch 0000/0160 | Loss: 0.3133\n",
      "| Epoch: 003/005 | Batch 0050/0160 | Loss: 0.3133\n",
      "| Epoch: 003/005 | Batch 0100/0160 | Loss: 0.3133\n",
      "| Epoch: 003/005 | Batch 0150/0160 | Loss: 0.3133\n",
      "| Epoch: 003/005 | Train Acc: 100.00% | Valid. Acc: 100.00%\n",
      "| Time elapsed: 1.72 min\n",
      "| Epoch: 004/005 | Batch 0000/0160 | Loss: 0.3133\n",
      "| Epoch: 004/005 | Batch 0050/0160 | Loss: 0.3133\n",
      "| Epoch: 004/005 | Batch 0100/0160 | Loss: 0.3133\n",
      "| Epoch: 004/005 | Batch 0150/0160 | Loss: 0.3133\n",
      "| Epoch: 004/005 | Train Acc: 100.00% | Valid. Acc: 100.00%\n",
      "| Time elapsed: 2.35 min\n",
      "| Epoch: 005/005 | Batch 0000/0160 | Loss: 0.3133\n",
      "| Epoch: 005/005 | Batch 0050/0160 | Loss: 0.3133\n",
      "| Epoch: 005/005 | Batch 0100/0160 | Loss: 0.3133\n",
      "| Epoch: 005/005 | Batch 0150/0160 | Loss: 0.3133\n",
      "| Epoch: 005/005 | Train Acc: 100.00% | Valid. Acc: 100.00%\n",
      "| Time elapsed: 2.99 min\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 5\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dataloader)\n",
    "    acc_val , loss_val = evaluate(val_dataloader)\n",
    "    print('| Epoch: %03d/%03d | Train Acc: %.2f%% | Valid. Acc: %.2f%%'\n",
    "          %(epoch + 1, num_epochs, 100 * acc_train, 100 * acc_val))\n",
    "    print(f'| Time elapsed: {(time.time() - start_time) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcfec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d524686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test, _ = evaluate(test_dataloader)\n",
    "print('Test Acc: %.2f%%'\n",
    "      %(100 * acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7d29ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb\n",
    "## https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2_lstm.ipynb\n",
    "sentiment_label = {1: \"high\",\n",
    "                   0: \"low\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    # evaluation mode (no gradients)\n",
    "    with torch.no_grad():\n",
    "        # tokenize and index the tokens\n",
    "        processed_text = torch.tensor(text_pipeline(text))\n",
    "        # add a batch dimension\n",
    "        processed_text = processed_text.unsqueeze(0).to(device)\n",
    "        # compute sequence length\n",
    "        text_length = processed_text.size(0)\n",
    "        # convert to tensor and add a batch dimension\n",
    "        text_length = torch.tensor(text_length).unsqueeze(0)\n",
    "        # prediction\n",
    "        prediction = model(processed_text, text_length)\n",
    "        # reduction real numbers to values between 0 and 1\n",
    "        probability = torch.sigmoid(prediction)\n",
    "        # get the max value of all elements\n",
    "        predicted_probability, predicted_class, = torch.max(probability, dim=1)\n",
    "        # convert tensor holding a single value into an integer\n",
    "        return predicted_class.item(), predicted_probability.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8797b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0 = low\n",
      "Probability: 0.7310488224029541\n"
     ]
    }
   ],
   "source": [
    "text = \"CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21\"\n",
    "pred_class, pred_proba = predict(text, text_pipeline)\n",
    "\n",
    "print(f'Predicted Class: {pred_class} = {sentiment_label[pred_class]}')\n",
    "print(f'Probability: {pred_proba}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aa9511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0 = low\n",
      "Probability: 0.7307953834533691\n"
     ]
    }
   ],
   "source": [
    "text = \"O=C(C#CCCN1CCOCC1)Nc1cc2c(Nc3ccc(F)c(Cl)c3)ncn\"\n",
    "pred_class, pred_proba = predict(text, text_pipeline)\n",
    "\n",
    "print(f'Predicted Class: {pred_class} = {sentiment_label[pred_class]}')\n",
    "print(f'Probability: {pred_proba}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e46357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b50b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
